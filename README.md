# machine-learning-a-z-hands-on-python-r-in-data-science
Machine Learning A-Zâ„¢: Hands-On Python &amp; R In Data Science by Kirill Eremenko, Hadelin de Ponteves
Udemy: https://www.udemy.com/course/machinelearning/?utm_source=adwords&utm_medium=udemyads&utm_campaign=Python_v.PROF_la.EN_cc.AU_ti.7380_Q3CP2021&utm_content=deal4584&utm_term=_._ag_131385199328_._ad_538583980684_._kw__._de_c_._dm__._pl__._ti_dsa-840427733208_._li_9071759_._pd__._&matchtype=b


## Key items taught:
* Training in both Python and R
 
## Content Info
### Part 2 - Regression
#### Section 4 - Simple Linear Regression
* Example of predicting salary based on age
#### Section 5 - Multiple Linear Regression
* Example of creating a model the see which company is the best for investing in based on the profit, but also related to R&D Spend, Administration Spend, Marketing Spend, State (Location)
* Can also find which State performs better
* Does spending more on marketing or R&D yield better profits
#### Section 6 - Polynomial Regression
* Example of predicting salary based on position in company
#### Section 7 - Support Vector Regression (SVR)
* Example of predicting salary based on position in company
* Good for non-linear datasets
* Can also be used for linear datasets based on kernels
#### Section 8 - Decision Tree Regression
* Example of predicting salary based on position in company
* Not good for 2-dimensional data sets

### Part 3 - Classification
#### Section 14 - Logistic Regression
* Example predict is tumor is benign or malignant, based on tumor features.
* Accurancy of 94.7%
### Section 15 - K-Nearest Neighbors (K-NN)
* Accurancy of 94.7%
### Section 16 - Support Vector Machine (SVM)
* Accurancy of 94.1%
### Section 17 - Kernel SVM
* Accurancy of 95.3%
### Section 18 - Naive Bayes
* Accurancy of 94.1%
### Section 19 - Decision Tree Classification
* Accurancy of 95.9%
### Section 20 - Random Forest Classification
* Accurancy of 93.5%

### Part 6 - Reinforcement Learning
#### Section 32 - Upper Confidence Bound (UCB)
* Example of finding the best ad design that converts customers to click the ad (potentially buy the car)
** Test 10 different ads across 10,000 users
#### Section 33 - Thompson Sampling
* Example of finding the best ad design that converts customers to click the ad (potentially buy the car)

### Part 8 - Deep Learning
#### Section 39 - Artificial Neural Networks (ANN)
* Example customer retention. Predict probability of customer leaving bank based on past customer features
#### Section 40 - Convolutional Neural Networks (CNN)
* Example training model on images of cats and dogs

## Part 9 - Dimensionality Reduction
#### Section 43 - Principal Component Analysis (PCA)
* Example of wine data set, with customer segment based on wine features. Firstly cluster the customer segments (already done into 3 segments). Then create a predictive model that predicts which new wines will belong to which customer segment.

#### Section 44 - Linear Discriminant Analysis (LDA)
* Example of wine data set, with custome
r segment based on wine features. Firstly cluster the customer segments (already done into 3 segments). Then create a predictive model that predicts which new wines will belong to which customer segment.

#### Section 45 - Kernel PCA
* Example of wine data set, with customer segment based on wine features. Firstly cluster the customer segments (already done into 3 segments). Then create a predictive model that predicts which new wines will belong to which customer segment.

### Part 10 - Model Selection _ Boosting
#### Section 49 - XGBoost
* Example predict is tumor is benign or malignant, based on tumor features.
